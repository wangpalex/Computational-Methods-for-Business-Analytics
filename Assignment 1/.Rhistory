res2_hist=hist(res2, breaks = 10^2, plot=FALSE)
plot(x,hx,xlab="",ylab="",main="",
col="blue",lty=2,type="l",lwd=1,ylim=c(0,max(c(res1_hist$density, res2_hist$density))))
mtext("beta^hat",side=1,line=2)
mtext("density",side=2, line=2)
lines(res1_hist$mids,res1_hist$density,
col="red",lty=1,lwd=1)
lines(res2_hist$mids,res2_hist$density,
col="green",lty=1,lwd=1)
legend("topleft",
legend=c("normal distribution",
"distribution of 100000 betas with N=100",
"distribution of 100000 betas with N=25"),
col=c("blue","red","green"),
lty=c(2,1,1),cex=0.8,bty = "n")
}
normality_check(res1,res2)
normality_check = function(res1, res2) {
# Test normality
library(nortest)
#Anderson-Darling normality test
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res1)
qqline(res1)
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res2)
qqline(res2)
# Plot density
# Call lm_reg and do the computation
library(doParallel)
cores=detectCores()
cl <- parallel::makeCluster(2, setup_strategy = "sequential")
registerDoParallel(cl)
stopCluster(cl)
# Plot the distribution of beta1^hat and normal distribution
x = seq(min(res1), max(res1), length=100)
hx = dnorm(x,mean=mean(res1),sd=sd(res1))
res1_hist=hist(res1, breaks = 10^2, plot=FALSE)
res2_hist=hist(res2, breaks = 10^2, plot=FALSE)
plot(x,hx,xlab="",ylab="",main="",
col="blue",lty=2,type="l",lwd=1,ylim=c(0,max(c(res1_hist$density, res2_hist$density))))
mtext("beta^hat",side=1,line=2)
mtext("density",side=2, line=2)
lines(res1_hist$mids,res1_hist$density,
col="red",lty=1,lwd=1)
lines(res2_hist$mids,res2_hist$density,
col="green",lty=1,lwd=1)
legend("topleft",
legend=c("normal distribution",
"distribution of 100000 betas with N=100",
"distribution of 100000 betas with N=25"),
col=c("blue","red","green"),
lty=c(2,1,1),cex=0.8,bty = "n")
}
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = runif(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = runif(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
library(MASS)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = runif(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
hist(res1)
res2 = vec_loop(rep(100,S))
hist(res2)
mean(res1) # 1.999372
mean(res2) # 2.000016
var(res1) # 0.003772373
var(res2) # 0.0008630136
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.3446
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = runif(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
res2 = vec_loop(rep(100,S))
mean(res1) # 1.999372
mean(res2) # 2.000016
var(res1) # 0.003772373
var(res2) # 0.0008630136
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.3446
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rcauchy(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
res2 = vec_loop(rep(100,S))
mean(res1) # 1.907382x
mean(res2) # -1.599096
var(res1) # 3427.213
var(res2) # 29851.75
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.05461
normality_check(res1,res2)
normality_check = function(res1, res2) {
# Test normality
library(nortest)
#Anderson-Darling normality test
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res1)
qqline(res1)
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res2)
qqline(res2)
# Plot density
# Call lm_reg and do the computation
library(doParallel)
cores=detectCores()
cl <- parallel::makeCluster(2, setup_strategy = "sequential")
registerDoParallel(cl)
stopCluster(cl)
# Plot the distribution of beta1^hat and normal distribution
x = seq(min(res1), max(res1), length=100)
hx = dnorm(x,mean=mean(res1),sd=sd(res1))
res1_hist=hist(res1, breaks = 10^2, plot=FALSE)
res2_hist=hist(res2, breaks = 10^2, plot=FALSE)
plot(x,hx,xlab="",ylab="",main="",
col="blue",lty=2,type="l",lwd=1,ylim=c(0,max(c(res1_hist$density, res2_hist$density))))
mtext("beta^hat",side=1,line=2)
mtext("density",side=2, line=2)
lines(res1_hist$mids,res1_hist$density,
col="red",lty=1,lwd=1)
lines(res2_hist$mids,res2_hist$density,
col="green",lty=1,lwd=1)
legend("topleft",
legend=c("normal distribution",
"distribution of 100000 betas with N=100",
"distribution of 100000 betas with N=25"),
col=c("blue","red","green"),
lty=c(2,1,1),cex=0.8,bty = "n")
}
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rnorm(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
hist(res1)
res2 = vec_loop(rep(100,S))
hist(res2)
mean(res1) # 2.002271
mean(res2) # 1.998513
var(res1) # 0.04465469
var(res2) # 0.01046778
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.1095
normality_check = function(res1, res2) {
# Test normality
library(nortest)
#Anderson-Darling normality test
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res1)
qqline(res1)
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res2)
qqline(res2)
# Plot density
# Call lm_reg and do the computation
library(doParallel)
cores=detectCores()
cl <- parallel::makeCluster(2, setup_strategy = "sequential")
registerDoParallel(cl)
stopCluster(cl)
# Plot the distribution of beta1^hat and normal distribution
x = seq(min(res1), max(res1), length=100)
hx = dnorm(x,mean=mean(res1),sd=sd(res1))
res1_hist=hist(res1, breaks = 10^2, plot=FALSE)
res2_hist=hist(res2, breaks = 10^2, plot=FALSE)
plot(x,hx,xlab="",ylab="",main="",
col="blue",lty=2,type="l",lwd=1,ylim=c(0,max(c(res1_hist$density, res2_hist$density))))
mtext("beta^hat",side=1,line=2)
mtext("density",side=2, line=2)
lines(res1_hist$mids,res1_hist$density,
col="red",lty=1,lwd=1)
lines(res2_hist$mids,res2_hist$density,
col="green",lty=1,lwd=1)
legend("topleft",
legend=c("normal distribution",
"distribution of 100000 betas with N=100",
"distribution of 100000 betas with N=25"),
col=c("blue","red","green"),
lty=c(2,1,1),cex=0.8,bty = "n")
}
normality_check(res1,res2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rnorm(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
knitr::opts_chunk$set(echo = TRUE)
#Print out the reduced row echelon form of given matrixes
library(quhomology)
library(Matrix)
A = matrix(c(1,1,2,2),nrow=2)
B = matrix(c(1,1,2,2,1,2),nrow=3)
C = matrix(c(1,1,2,0),nrow=2)
D = matrix(c(1,2,3,2,0,2),nrow=3)
rankMatrix(A)
rankMatrix(B)
rankMatrix(C)
rankMatrix(D)
# Load the required package
library(dplyr)
df <- read.csv("exercise_and_cholesterol.csv")
df_young <- df %>% filter(df$Age == "Young")
df_old <- df %>% filter(df$Age == "Old")
plot(df$Exercise, df$Cholesterol,
col = ifelse(df$Age == "Young", "blue", "red"),
pch = ifelse(df$Age == "Young", 17, 19),
xlab = "Exercise",
ylab = "Cholesterol",
xlim = c(6, 18),
ylim = c(35, 50))
# Add the fitted regression line for the combined data
abline(lm(df$Cholesterol~df$Exercise), lty = 1, lwd = 2)
# Add the fitted regression line for subgroups, lty specifies the line type, lwd specifies the line width
abline(lm(df_young$Cholesterol~df_young$Exercise), lty = 3, col = "blue")
abline(lm(df_old$Cholesterol~df_old$Exercise), lty = 2, col = "red")
legend("topleft",
#pch = c(19, 17),
lty = c(2,3,1),
c("Old Only", "Young Only", "Combined Data"),
col = c("red", "blue", "black"))
plot(df$Exercise, df$Cholesterol,
col = ifelse(df$Age == "Young", "blue", "red"),
pch = ifelse(df$Age == "Young", 17, 19),
xlab = "Exercise",
ylab = "Cholesterol",
xlim = c(6, 18),
ylim = c(35, 50))
abline(lm(df$Cholesterol~df$Exercise + df$Age), lty = 1, lwd = 2)
abline(lm(df_young$Cholesterol~df_young$Exercise), lty = 3, col = "blue")
abline(lm(df_old$Cholesterol~df_old$Exercise), lty = 2, col = "red")
legend("topleft",
#pch = c(19, 17),
lty = c(2,3,1),
c("Old Only", "Young Only", "Combined Data"),
col = c("red", "blue", "black"))
summary(lm(df$Cholesterol~df$Exercise+df$Age))
set.seed(37)
# Data generation
x = rnorm(1000) # Sample 1000 points from N(0, 1)
e = rnorm(1000)
y = 0.7 + 2*x + e
plot(y ~ x)
# Use lm()
model = lm(y ~ x)
summary(model)
# y = 0.734 + 1.954 * x
# Use matrix algebra
X = cbind(rep(1,1000),x) # Add bias(constant for intercept) to data matrix
Y = y
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rnorm(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rnorm(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
library(MASS)
# Use matrix algebra
X = cbind(rep(1,1000),x) # Add bias(constant for intercept) to data matrix
Y = y
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta_h # \beta0 = 0.734, \beta1 = 1.954
plot(y ~ x)
abline(model$coefficients[1],model$coefficients[2],col="green")
abline(beta_h[1],beta_h[2],col="red",lty="dashed")
legend(-3,8,legend=c("lm()", "Matrix algebra"),col=c("green","red"),lty=c("dashed","dashed"))
library(MASS)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rnorm(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
res2 = vec_loop(rep(100,S))
mean(res1) # 2.002271
mean(res2) # 1.998513
var(res1) # 0.04465469
var(res2) # 0.01046778
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.1095
normality_check = function(res1, res2) {
# Test normality
library(nortest)
#Anderson-Darling normality test
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res1)
qqline(res1)
print(ad.test(res1)) # p-value = 2.064e-08
qqnorm(res2)
qqline(res2)
# Plot density
# Call lm_reg and do the computation
library(doParallel)
cores=detectCores()
cl <- parallel::makeCluster(2, setup_strategy = "sequential")
registerDoParallel(cl)
stopCluster(cl)
# Plot the distribution of beta1^hat and normal distribution
x = seq(min(res1), max(res1), length=100)
hx = dnorm(x,mean=mean(res1),sd=sd(res1))
res1_hist=hist(res1, breaks = 10^2, plot=FALSE)
res2_hist=hist(res2, breaks = 10^2, plot=FALSE)
plot(x,hx,xlab="",ylab="",main="",
col="blue",lty=2,type="l",lwd=1,ylim=c(0,max(c(res1_hist$density, res2_hist$density))))
mtext("beta^hat",side=1,line=2)
mtext("density",side=2, line=2)
lines(res1_hist$mids,res1_hist$density,
col="red",lty=1,lwd=1)
lines(res2_hist$mids,res2_hist$density,
col="green",lty=1,lwd=1)
legend("topleft",
legend=c("normal distribution",
"distribution of 100000 betas with N=100",
"distribution of 100000 betas with N=25"),
col=c("blue","red","green"),
lty=c(2,1,1),cex=0.8,bty = "n")
}
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = runif(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
res2 = vec_loop(rep(100,S))
mean(res1) # 1.999372
mean(res2) # 2.000016
var(res1) # 0.003772373
var(res2) # 0.0008630136
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.3446
normality_check(res1,res2)
set.seed(37)
S = 10000
single_loop = function(N) {
x = rnorm(N)
e = rcauchy(N)
Y = 0.7 + 2*x + e
X = cbind(rep(1,N),x)
beta_h = ginv(t(X)%*%X)%*%t(X)%*%Y
beta1 = beta_h[2]
}
vec_loop = Vectorize(single_loop)
res1 = vec_loop(rep(25,S))
res2 = vec_loop(rep(100,S))
mean(res1) # 1.907382x
mean(res2) # -1.599096
var(res1) # 3427.213
var(res2) # 29851.75
t.test(res1, res2, alternative = "two.sided", var.equal = FALSE) # p-value = 0.05461
normality_check(res1,res2)
library(numDeriv)
obj_func = function(r, x0=10000,p=250, n=60) {
# Iteration method to calculate xn
x = x0
for(i in 1:n) {
x = x*(1+r) - p
}
res = x
}
analytical_func = function(r, x0=10000,p=250, n=60) {
# Close form of xn
xn = x0*(1+r)^n + p*(1-(1+r)^n)/r
}
bisection_method = function(f,left,right,tol=1e-10,n=1000) {
if(sign(f(left))==sign(f(right))) {
print("Bad Initial Points!")
stop()
}
history = right
for (i in 1:n) {
mid = (left+right)/2
if (f(mid)==0) {
history = c(history,mid)
res = list('optim r' = mid, 'iterations' = i,'history'=history)
return(res)
} else if (sign(f(mid))==sign(f(right))) {
right = mid
history = c(history,right)
} else {
left = mid
history = c(history,left)
}
if(abs(left-right) < tol) {
res = list('optim r' = mid, 'iterations' = i,'history'=history)
return(res)
}
}
print("Maximum number of iteration reached")
res = list('optim r' = mid, 'iterations' = i,'history'=history)
return(res)
}
newton_method = function(f, r0, tol=1e-8,n=1000) {
history = r0
for(i in 1:n) {
deriv = genD(func = f, x = r0)$D
r1 = r0 - f(r0)/deriv[1]
history = c(history,r1)
if(abs(r1-r0) < tol) {
res = list('optim r' = r1, 'iterations' = i,'history'=history)
return(res)
}
r0 = r1
}
print("Maximum number of iteration reached")
res = list('optim r' = r1, 'iterations' = i,'history'=history)
return(res)
}
sol1 = newton_method(obj_func, 0.01)
sol1$`optim r`
sol2 = newton_method(analytical_func, 0.02)
sol3 = newton_method(analytical_func, 0.03)
sol4 = bisection_method(obj_func, 0.01, 0.025)
sol5 = bisection_method(analytical_func, 0.01, 0.015)
mat = cbind(sol1$history,sol2$history,sol3$history)
maxLen = nrow(mat)
plot(1:length(sol5$history),sol5$history,type="b",pch=20,col="blue",ylim=c(0.01,0.03),xlab="iterations",ylab="r")
abline(sol1$`optim r`,0,col="red")
lines(1:length(sol2$history),sol2$history,type="b",pch=20,col="red")
lines(1:length(sol1$history),sol1$history,type="b",pch=20,col="green")
lines(1:length(sol4$history),sol4$history,type="b",pch=20,col="purple")
lines(1:length(sol3$history),sol3$history,type="b",pch=20,col="orange")
